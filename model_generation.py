#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ç”Ÿæˆè„šæœ¬

åŠŸèƒ½ï¼š
1. è®­ç»ƒU-Netæ¨¡å‹
2. è®­ç»ƒMRA-Netæ¨¡å‹
3. æ¨¡å‹è¯„ä¼°å’Œä¿å­˜
python model_generation.py --mode both --epochs_unet 50 --epochs_mranet 30
ä½¿ç”¨æ–¹æ³•ï¼š
    python model_generation.py
"""

import os
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import h5py
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
from tqdm import tqdm
import cv2
import contextlib

# æ·»åŠ toolsç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))

from unet_model import UNet
from enhanced_mra_net_model import EnhancedMRANet, EnhancedMRANetLoss
from mras_net_model import MRANetLoss
from logger import get_logger

class ImageDataset(Dataset):
    """å›¾åƒæ•°æ®é›†ç±» - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, dataset_path: str, transform=None, preload=True, target_size=(256, 256)):
        """
        åˆå§‹åŒ–å›¾åƒæ•°æ®é›†
        
        Args:
            dataset_path: HDF5æ•°æ®é›†è·¯å¾„
            transform: æ•°æ®å¢å¼ºè½¬æ¢
            preload: æ˜¯å¦é¢„åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼Œå¤šè¿›ç¨‹åŠ è½½æ—¶å¿…é¡»ä¸ºTrue
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        """
        self.dataset_path = dataset_path
        self.transform = transform
        self.target_size = target_size
        self.psf_target_size = (64, 64)  # PSFç›®æ ‡å°ºå¯¸
        
        # å¼ºåˆ¶é¢„åŠ è½½æ¨¡å¼ï¼Œè§£å†³h5pyå¯¹è±¡ä¸èƒ½è¢«åºåˆ—åŒ–çš„é—®é¢˜
        # è¿™å¯¹äºå¤šè¿›ç¨‹æ•°æ®åŠ è½½æ˜¯å¿…è¦çš„
        with h5py.File(dataset_path, 'r') as h5_file:
            self.clean_images = h5_file['clean_images'][:]
            self.blurred_images = h5_file['blurred_images'][:]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰PSFæ•°æ®
            self.has_psfs = 'psfs' in h5_file
            if self.has_psfs:
                self.psfs = []
                psfs_group = h5_file['psfs']
                # é¢„å¤„ç†å¹¶ç¼“å­˜æ‰€æœ‰PSF
                for i in range(len(self.clean_images)):
                    psf_key = f'item_{i}'
                    if psf_key in psfs_group:
                        psf_img = psfs_group[psf_key][:]
                        # é¢„å…ˆè°ƒæ•´PSFå°ºå¯¸
                        if psf_img.shape != self.psf_target_size:
                            psf_img = cv2.resize(psf_img, self.psf_target_size, interpolation=cv2.INTER_LINEAR)
                        self.psfs.append(psf_img)
                    else:
                        self.psfs.append(None)
            else:
                self.psfs = None
    
    def __len__(self):
        return len(self.clean_images)
    
    def __getitem__(self, idx):
        clean_img = self.clean_images[idx]
        blurred_img = self.blurred_images[idx]
        
        # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´ - è°ƒæ•´ä¸ºç›¸åŒå¤§å°
        if clean_img.shape != self.target_size:
            clean_img = cv2.resize(clean_img, self.target_size, interpolation=cv2.INTER_LINEAR)
        
        if blurred_img.shape != self.target_size:
            blurred_img = cv2.resize(blurred_img, self.target_size, interpolation=cv2.INTER_LINEAR)
        
        # è½¬æ¢ä¸ºå¼ é‡å¹¶æ·»åŠ é€šé“ç»´åº¦
        clean = torch.from_numpy(clean_img).float().unsqueeze(0)
        blurred = torch.from_numpy(blurred_img).float().unsqueeze(0)
        
        # å¤„ç†PSFæ•°æ®
        if self.has_psfs and self.psfs is not None and idx < len(self.psfs):
            psf_img = self.psfs[idx]
            if psf_img is not None:
                psf = torch.from_numpy(psf_img).float().unsqueeze(0)
                return blurred, clean, psf
        
        return blurred, clean

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, device: str = None, output_dir: str = "outputs/models",
                 amp_mode: str = 'auto', num_workers: int = 4, pin_memory_mode: str = 'auto'):
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.output_dir = output_dir
        self.logger = get_logger(__name__)
        # è¿è¡Œæ—¶å¯é…ç½®é¡¹
        self.has_cuda = (self.device == 'cuda' and torch.cuda.is_available())
        self.amp_mode = amp_mode  # 'auto' | 'on' | 'off'
        self.num_workers = max(int(num_workers), 0)
        self.pin_memory_mode = pin_memory_mode  # 'auto' | 'on' | 'off'
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        self.logger.info(f"æ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def train_unet(self, 
                   train_dataset_path: str,
                   val_dataset_path: str = None,
                   epochs: int = 100,
                   batch_size: int = 8,
                   learning_rate: float = 1e-4) -> str:
        """
        è®­ç»ƒU-Netæ¨¡å‹
        
        Args:
            train_dataset_path: è®­ç»ƒæ•°æ®é›†è·¯å¾„
            val_dataset_path: éªŒè¯æ•°æ®é›†è·¯å¾„
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            
        Returns:
            æ¨¡å‹ä¿å­˜è·¯å¾„
        """
        self.logger.info("å¼€å§‹è®­ç»ƒU-Netæ¨¡å‹")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - é«˜æ€§èƒ½ç‰ˆæœ¬
        self.logger.info("åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨...")
        # ç¦ç”¨é¢„åŠ è½½æ¨¡å¼ï¼Œé¿å…å†…å­˜é—®é¢˜
        train_dataset = ImageDataset(
            train_dataset_path,
            preload=False,  # ç¦ç”¨é¢„åŠ è½½é¿å…å†…å­˜é—®é¢˜
            target_size=(256, 256)  # ç¡®ä¿æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
        )
        self.logger.info(f"è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_dataset)}")
        
        # å¢åŠ num_workerså®ç°å¤šçº¿ç¨‹åŠ è½½ï¼Œpin_memoryåŠ é€ŸCPUåˆ°GPUçš„æ•°æ®ä¼ è¾“
        if self.pin_memory_mode == 'on':
            pin_mem = True
        elif self.pin_memory_mode == 'off':
            pin_mem = False
        else:
            pin_mem = self.has_cuda
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=self.num_workers,  # ä½¿ç”¨å¤šä¸ªå·¥ä½œçº¿ç¨‹åŠ è½½æ•°æ®
            pin_memory=pin_mem,  # ä»…åœ¨CUDAå¯ç”¨æ—¶å¯ç”¨
            prefetch_factor=2,  # é¢„åŠ è½½å› å­
            persistent_workers=(self.num_workers > 0)  # ä»…å½“æœ‰workeræ—¶å¯ç”¨
        )
        
        val_loader = None
        if val_dataset_path and os.path.exists(val_dataset_path):
            self.logger.info("åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨...")
            val_dataset = ImageDataset(
                val_dataset_path,
                preload=True,  # é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
                target_size=(256, 256)
            )
            self.logger.info(f"éªŒè¯æ•°æ®é›†å¤§å°: {len(val_dataset)}")
            
            val_loader = DataLoader(
                val_dataset, 
                batch_size=batch_size*2,  # éªŒè¯æ—¶å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡
                shuffle=False,
                num_workers=self.num_workers,
                pin_memory=pin_mem,
                persistent_workers=(self.num_workers > 0)  # ä»…å½“æœ‰workeræ—¶å¯ç”¨
            )
        
        # åˆ›å»ºæ¨¡å‹
        model = UNet(n_channels=1, n_classes=1, bilinear=False)
        model = model.to(self.device)
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
        
        # è®­ç»ƒå†å²
        train_losses = []
        val_losses = []
        
        best_val_loss = float('inf')
        best_model_path = os.path.join(self.output_dir, "best_unet.pth")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            
            train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]")
            for batch_idx, batch_data in enumerate(train_pbar):
                # å¤„ç†æ•°æ®æ‰¹æ¬¡ï¼Œå…¼å®¹æœ‰PSFå’Œæ— PSFçš„æƒ…å†µ
                if len(batch_data) == 3:  # å¦‚æœåŒ…å«PSF
                    blurred, clean, _ = batch_data  # å¿½ç•¥PSFæ•°æ®
                else:  # å¦‚æœåªæœ‰æ¨¡ç³Šå›¾åƒå’Œæ¸…æ™°å›¾åƒ
                    blurred, clean = batch_data
                blurred = blurred.to(self.device)
                clean = clean.to(self.device)
                
                optimizer.zero_grad()
                outputs = model(blurred)
                loss = criterion(outputs, clean)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                train_pbar.set_postfix({'loss': loss.item()})
            
            train_loss /= len(train_loader)
            train_losses.append(train_loss)
            
            # éªŒè¯é˜¶æ®µ
            if val_loader:
                model.eval()
                val_loss = 0.0
                
                with torch.no_grad():
                    val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]")
                    for data in val_pbar:
                        try:
                            # å¤„ç†æ•°æ®åŠ è½½å™¨è¿”å›çš„ä¸åŒæƒ…å†µ
                            if isinstance(data, (list, tuple)) and len(data) == 3:  # å¦‚æœè¿”å›ä¸‰ä¸ªå€¼ (blurred, clean, psf)
                                blurred, clean, _ = data  # å¿½ç•¥PSFæ•°æ®
                            elif isinstance(data, (list, tuple)) and len(data) == 2:  # å¦‚æœè¿”å›ä¸¤ä¸ªå€¼ (blurred, clean)
                                blurred, clean = data
                            else:
                                self.logger.warning(f"éªŒè¯æ•°æ®åŠ è½½å™¨è¿”å›äº†æ„å¤–çš„æ•°æ®æ ¼å¼: {type(data)}, {len(data) if isinstance(data, (list, tuple)) else 'éåˆ—è¡¨/å…ƒç»„'}")
                                continue
                                
                            blurred = blurred.to(self.device, non_blocking=True)
                            clean = clean.to(self.device, non_blocking=True)
                            
                            outputs = model(blurred)
                            loss = criterion(outputs, clean)
                            val_loss += loss.item()
                            val_pbar.set_postfix({'loss': loss.item()})
                        except Exception as e:
                            self.logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                            continue
                
                val_loss /= len(val_loader)
                val_losses.append(val_loss)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'train_loss': train_loss,
                        'val_loss': val_loss,
                    }, best_model_path)
                
                # ä½¿ç”¨æ–°çš„å­¦ä¹ ç‡è°ƒåº¦å™¨
                scheduler.step(val_loss)
                
                self.logger.info(f"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}")
            else:
                # æ²¡æœ‰éªŒè¯æ•°æ®æ—¶ï¼Œä½¿ç”¨è®­ç»ƒæŸå¤±ä½œä¸ºè°ƒåº¦å™¨çš„æŒ‡æ ‡
                scheduler.step(train_loss)
                self.logger.info(f"Epoch {epoch+1}: Train Loss = {train_loss:.6f}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(self.output_dir, "final_unet.pth")
        torch.save({
            'epoch': epochs,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_losses': train_losses,
            'val_losses': val_losses,
        }, final_model_path)
        
        # ä¿å­˜è®­ç»ƒå†å²å›¾è¡¨
        self._plot_training_history(train_losses, val_losses, "unet_training_history.png")
        
        self.logger.info(f"U-Netè®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹ä¿å­˜åˆ°: {best_model_path}")
        return best_model_path
    
    def train_mra_net(self, 
                      train_dataset_path: str,
                      val_dataset_path: str = None,
                      epochs: int = 100,  # ä¸U-Netä¿æŒä¸€è‡´ï¼Œå¢åŠ è®­ç»ƒè½®æ•°
                      batch_size: int = 8,  # ä¸U-Netä¿æŒä¸€è‡´ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
                      learning_rate: float = 1e-4,
                      loss_weights: Optional[Dict[str, float]] = None) -> str:
        """
        è®­ç»ƒMRA-Netæ¨¡å‹ (å¿«é€ŸéªŒè¯ç‰ˆæœ¬)
        
        Args:
            train_dataset_path: è®­ç»ƒæ•°æ®é›†è·¯å¾„
            val_dataset_path: éªŒè¯æ•°æ®é›†è·¯å¾„
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            
        Returns:
            æ¨¡å‹ä¿å­˜è·¯å¾„
        """
        self.logger.info("å¼€å§‹è®­ç»ƒMRA-Netæ¨¡å‹ (å¿«é€ŸéªŒè¯ç‰ˆ)")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - é«˜æ€§èƒ½ç‰ˆæœ¬
        self.logger.info("åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨...")
        # ç»Ÿä¸€æ•°æ®åŠ è½½ç­–ç•¥ï¼Œä¸U-Netä¿æŒä¸€è‡´
        train_dataset = ImageDataset(
            train_dataset_path,
            preload=False,  # ä¸U-Netä¿æŒä¸€è‡´ï¼Œé¿å…å†…å­˜é—®é¢˜
            target_size=(256, 256)  # ç¡®ä¿æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
        )
        self.logger.info(f"è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_dataset)}")
        
        # ä¼˜åŒ–æ•°æ®åŠ è½½å™¨é…ç½®ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦
        has_cuda = self.has_cuda
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=self.num_workers,  # å¯ç”¨å¤šçº¿ç¨‹åŠ è½½
            pin_memory=(True if self.pin_memory_mode=='on' else False if self.pin_memory_mode=='off' else has_cuda),
            persistent_workers=(self.num_workers > 0)  # ä»…å½“æœ‰workeræ—¶å¯ç”¨
        )
        
        val_loader = None
        if val_dataset_path and os.path.exists(val_dataset_path):
            self.logger.info("åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨...")
            val_dataset = ImageDataset(
                val_dataset_path,
                preload=False,  # ä¸U-Netä¿æŒä¸€è‡´
                target_size=(256, 256)  # ç¡®ä¿æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
            )
            self.logger.info(f"éªŒè¯æ•°æ®é›†å¤§å°: {len(val_dataset)}")
            
            val_loader = DataLoader(
                val_dataset, 
                batch_size=batch_size*2,  # éªŒè¯æ—¶ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡
                shuffle=False,
                num_workers=self.num_workers,  # å¯ç”¨å¤šçº¿ç¨‹åŠ è½½
                pin_memory=(True if self.pin_memory_mode=='on' else False if self.pin_memory_mode=='off' else has_cuda),  # ä»…åœ¨CUDAå¯ç”¨æ—¶å¯ç”¨
                persistent_workers=(self.num_workers > 0)  # ä»…å½“æœ‰workeræ—¶å¯ç”¨
            )
        
        # åˆ›å»ºå¢å¼ºç‰ˆMRA-Netæ¨¡å‹ - å¢åŠ æ¨¡å‹å®¹é‡ä»¥æå‡æ€§èƒ½
        model = EnhancedMRANet(num_stages=12, hidden_channels=128)  # å¢åŠ é˜¶æ®µæ•°å’Œé€šé“æ•°
        model = model.to(self.device)
        
        # æ‰“å°æ¨¡å‹å‚æ•°ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        self.logger.info(f"MRA-Netæ¨¡å‹å‚æ•°: æ€»è®¡ {total_params:,}, å¯è®­ç»ƒ {trainable_params:,}")
        self.logger.info(f"æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # ä¼˜åŒ–æŸå¤±å‡½æ•°é…ç½®ï¼Œå¯ç”±å¤–éƒ¨æƒé‡è¦†ç›–
        lw = loss_weights or {}
        lambda_physics = float(lw.get('physics', 0.5))
        lambda_perceptual = float(lw.get('perceptual', 0.2))
        lambda_edge = float(lw.get('edge', 0.3))
        lambda_ssim = float(lw.get('ssim', 0.4))
        criterion = EnhancedMRANetLoss(
            lambda_physics=lambda_physics,
            lambda_perceptual=lambda_perceptual,
            lambda_edge=lambda_edge,
            lambda_ssim=lambda_ssim
        )
        criterion = criterion.to(self.device)
        
        # ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œä¼˜åŒ–æƒé‡è¡°å‡å’Œå­¦ä¹ ç‡
        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5, betas=(0.9, 0.999), eps=1e-8)
        
        # æ”¹è¿›çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=20, T_mult=2, eta_min=1e-6  # å¢åŠ é‡å¯å‘¨æœŸï¼Œæé«˜æ”¶æ•›ç¨³å®šæ€§
        )
        
        # æ·»åŠ æ¢¯åº¦è£å‰ª
        max_grad_norm = 1.0
        
        # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œæé«˜è®­ç»ƒé€Ÿåº¦
        # AMP å¼€å…³æŒ‰å‚æ•°è¦†ç›–
        if self.amp_mode == 'on':
            use_amp = has_cuda
        elif self.amp_mode == 'off':
            use_amp = False
        else:
            use_amp = has_cuda  # auto
        # ä½¿ç”¨æ–°APIï¼štorch.amp.GradScaler('cuda', ...)
        scaler = torch.amp.GradScaler('cuda', enabled=use_amp) if has_cuda else torch.amp.GradScaler('cuda', enabled=False)
        autocast_ctx = torch.amp.autocast('cuda') if use_amp else contextlib.nullcontext()
        
        # è®­ç»ƒå†å²
        train_losses = []
        val_losses = []
        
        best_val_loss = float('inf')
        best_model_path = os.path.join(self.output_dir, "best_mra_net_fast.pth")
        
        # æ‰“å°GPUä¿¡æ¯
        if torch.cuda.is_available():
            self.logger.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
            self.logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
            
        # è®¾ç½®CUDAç›¸å…³ä¼˜åŒ–ï¼Œä»…åœ¨GPUå¯ç”¨æ—¶å¯ç”¨
        if has_cuda:
            torch.backends.cudnn.benchmark = True  # å¯ç”¨cuDNNè‡ªåŠ¨è°ƒä¼˜
            torch.backends.cudnn.fastest = True  # ä½¿ç”¨æœ€å¿«çš„ç®—æ³•
            torch.backends.cudnn.deterministic = False  # ç¦ç”¨ç¡®å®šæ€§ä»¥æé«˜æ€§èƒ½
            self.logger.info("å·²å¯ç”¨cuDNN benchmarkå’Œfastestæ¨¡å¼ä»¥ä¼˜åŒ–æ€§èƒ½")
            # æ¸…ç†GPUç¼“å­˜ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ˜¾å­˜
            torch.cuda.empty_cache()
        else:
            self.logger.info("CUDAä¸å¯ç”¨ï¼šå·²ç¦ç”¨AMPã€pin_memoryä¸cuDNNä¼˜åŒ–ï¼Œé‡‡ç”¨CPUè®­ç»ƒè·¯å¾„")
        
        # æ·»åŠ æ—©åœæœºåˆ¶ï¼Œé¿å…è¿‡åº¦è®­ç»ƒ
        patience = 10
        no_improve_epochs = 0
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            epoch_start_time = time.time()
            
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            
            train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]")
            for batch_idx, data in enumerate(train_pbar):
                try:
                    if len(data) == 3:  # æœ‰PSFæ•°æ®
                        blurred, clean, psf = data
                        psf = psf.to(self.device, non_blocking=True)
                    else:  # æ²¡æœ‰PSFæ•°æ®
                        blurred, clean = data
                        psf = None
                    
                    blurred = blurred.to(self.device, non_blocking=True)
                    clean = clean.to(self.device, non_blocking=True)
                    
                    optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶
                    
                    # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆæˆ–ç©ºä¸Šä¸‹æ–‡ï¼‰
                    with autocast_ctx:
                        # ç¡®ä¿è¾“å…¥æ•°æ®ç±»å‹ä¸€è‡´
                        blurred = blurred.float()
                        # MRANet.forward()åªæ¥å—ä¸€ä¸ªå‚æ•°
                        outputs, model_psf = model(blurred)
                        
                        # å°†æ¨¡å‹å¯¹è±¡ä½œä¸ºç¬¬ä¸‰ä¸ªå‚æ•°ä¼ é€’ç»™criterion
                        loss_dict = criterion(outputs, clean, model)
                        # ä»æŸå¤±å­—å…¸ä¸­æå–æ€»æŸå¤±
                        total_loss = loss_dict['total_loss']
                    
                    # ä½¿ç”¨æ¢¯åº¦ç¼©æ”¾å™¨è¿›è¡Œåå‘ä¼ æ’­
                    scaler.scale(total_loss).backward()
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
                    scaler.step(optimizer)
                    scaler.update()
                    
                    train_loss += total_loss.item()
                    
                    # ç®€åŒ–è¿›åº¦æ¡ä¿¡æ¯ï¼Œé¿å…å¤æ‚çš„GPUæŸ¥è¯¢
                    if batch_idx % 10 == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ›´æ–°ä¸€æ¬¡
                        train_pbar.set_postfix({
                            'loss': f"{total_loss.item():.4f}"
                        })
                    
                except RuntimeError as e:
                    # æ•è·å¹¶å¤„ç†å¯èƒ½çš„CUDAé”™è¯¯
                    self.logger.error(f"æ‰¹æ¬¡ {batch_idx} å‘ç”ŸCUDAé”™è¯¯: {str(e)}")
                    torch.cuda.empty_cache()  # æ¸…ç†GPUå†…å­˜
                    continue
                except Exception as e:
                    self.logger.error(f"æ‰¹æ¬¡ {batch_idx} å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
                    torch.cuda.empty_cache()
                    continue
            
            train_loss /= len(train_loader)
            train_losses.append(train_loss)
            
            # éªŒè¯é˜¶æ®µ
            if val_loader:
                model.eval()
                val_loss = 0.0
                
                with torch.no_grad():
                    val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]")
                    for data in val_pbar:
                        if len(data) == 3:
                            blurred, clean, psf = data
                            psf = psf.to(self.device, non_blocking=True)
                        else:
                            blurred, clean = data
                            psf = None
                        
                        blurred = blurred.to(self.device, non_blocking=True)
                        clean = clean.to(self.device, non_blocking=True)
                        
                        # ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œæ¨ç†ï¼ˆæˆ–ç©ºä¸Šä¸‹æ–‡ï¼‰
                        with autocast_ctx:
                            # MRANet.forward()åªæ¥å—ä¸€ä¸ªå‚æ•°
                            outputs, model_psf = model(blurred)
                            # å°†æ¨¡å‹å¯¹è±¡ä½œä¸ºç¬¬ä¸‰ä¸ªå‚æ•°ä¼ é€’ç»™criterion
                            loss_dict = criterion(outputs, clean, model)
                            # ä»æŸå¤±å­—å…¸ä¸­æå–æ€»æŸå¤±
                            total_loss = loss_dict['total_loss']
                        
                        val_loss += total_loss.item()
                        val_pbar.set_postfix({'loss': total_loss.item()})
                
                val_loss /= len(val_loader)
                val_losses.append(val_loss)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'train_loss': train_loss,
                        'val_loss': val_loss,
                    }, best_model_path)
                    self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {val_loss:.6f}")
                    no_improve_epochs = 0
                else:
                    no_improve_epochs += 1
                    if no_improve_epochs >= patience:
                        self.logger.info(f"æ—©åœï¼š{patience}è½®æœªæ”¹å–„ï¼Œåœæ­¢è®­ç»ƒ")
                        break
                
                scheduler.step(val_loss)
                
                # è®¡ç®—å¹¶è®°å½•æ¯ä¸ªepochçš„æ—¶é—´
                epoch_time = time.time() - epoch_start_time
                self.logger.info(
                    f"Epoch {epoch+1}/{epochs}, è®­ç»ƒæŸå¤±: {train_loss:.6f}, éªŒè¯æŸå¤±: {val_loss:.6f}, "
                    f"ç”¨æ—¶: {epoch_time:.2f}ç§’"
                )
            else:
                # è®¡ç®—å¹¶è®°å½•æ¯ä¸ªepochçš„æ—¶é—´
                epoch_time = time.time() - epoch_start_time
                self.logger.info(
                    f"Epoch {epoch+1}/{epochs}, è®­ç»ƒæŸå¤±: {train_loss:.6f}, "
                    f"ç”¨æ—¶: {epoch_time:.2f}ç§’"
                )
                
                # æ²¡æœ‰éªŒè¯é›†æ—¶ï¼Œæ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼ˆå‡å°‘ä¿å­˜é¢‘ç‡ï¼‰
                if (epoch + 1) % 5 == 0:
                    checkpoint_path = os.path.join(self.output_dir, f"mra_net_epoch_{epoch+1}.pth")
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'train_loss': train_loss,
                    }, checkpoint_path)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(self.output_dir, "final_mra_net.pth")
        torch.save({
            'epoch': epochs,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_losses': train_losses,
            'val_losses': val_losses,
        }, final_model_path)
        
        # ä¿å­˜è®­ç»ƒå†å²å›¾è¡¨
        self._plot_training_history(train_losses, val_losses, "mra_net_training_history.png")
        
        self.logger.info(f"MRA-Netè®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹ä¿å­˜åˆ°: {best_model_path}")
        return best_model_path
    
    def _plot_training_history(self, train_losses: List[float], val_losses: List[float], filename: str):
        """ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨"""
        plt.figure(figsize=(10, 6))
        plt.plot(train_losses, label='Training Loss', color='blue')
        if val_losses:
            plt.plot(val_losses, label='Validation Loss', color='red')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training History')
        plt.legend()
        plt.grid(True)
        
        chart_path = os.path.join(self.output_dir, filename)
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}")
    
    def evaluate_model(self, model_path: str, test_dataset_path: str, model_type: str = "unet") -> Dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        self.logger.info(f"å¼€å§‹è¯„ä¼°{model_type}æ¨¡å‹")
        
        # åŠ è½½æ¨¡å‹
        if model_type.lower() == "unet":
            model = UNet(n_channels=1, n_classes=1, bilinear=False)
        else:  # mra_net
            model = EnhancedMRANet(num_stages=12, hidden_channels=128)  # ä½¿ç”¨å¢å¼ºé…ç½®
        
        checkpoint = torch.load(model_path, map_location=self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(self.device)
        model.eval()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_dataset = ImageDataset(test_dataset_path)
        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
        
        # è¯„ä¼°æŒ‡æ ‡
        total_loss = 0.0
        criterion = nn.MSELoss()
        
        with torch.no_grad():
            for data in tqdm(test_loader, desc="Evaluating"):
                if len(data) == 3 and model_type.lower() == "mra_net":
                    blurred, clean, psf = data
                    psf = psf.to(self.device)
                    outputs = model(blurred.to(self.device), psf)
                else:
                    blurred, clean = data[:2]
                    outputs = model(blurred.to(self.device))
                
                loss = criterion(outputs, clean.to(self.device))
                total_loss += loss.item()
        
        avg_loss = total_loss / len(test_loader)
        
        results = {
            'model_type': model_type,
            'model_path': model_path,
            'test_dataset_path': test_dataset_path,
            'average_loss': avg_loss,
            'num_test_samples': len(test_dataset)
        }
        
        self.logger.info(f"{model_type}æ¨¡å‹è¯„ä¼°å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¨¡å‹è®­ç»ƒç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['unet', 'mranet', 'both', 'interactive'], 
                       default='interactive', help='è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--train_path', default='outputs/datasets/train_dataset.h5',
                       help='è®­ç»ƒæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--val_path', default='outputs/datasets/val_dataset.h5',
                       help='éªŒè¯æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--epochs_unet', type=int, default=100, help='U-Netè®­ç»ƒè½®æ•°')
    parser.add_argument('--epochs_mranet', type=int, default=100, help='MRA-Netè®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size_unet', type=int, default=8, help='U-Netæ‰¹æ¬¡å¤§å°')
    parser.add_argument('--batch_size_mranet', type=int, default=8, help='MRA-Netæ‰¹æ¬¡å¤§å°')
    # æ–°å¢è¿è¡Œæ—¶æ§åˆ¶å‚æ•°
    parser.add_argument('--amp', dest='amp', action='store_true', help='å¼ºåˆ¶å¼€å¯AMPæ··åˆç²¾åº¦')
    parser.add_argument('--no-amp', dest='no_amp', action='store_true', help='å¼ºåˆ¶å…³é—­AMPæ··åˆç²¾åº¦')
    parser.add_argument('--num-workers', dest='num_workers', type=int, default=4, help='DataLoaderå·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('--pin-memory', dest='pin_memory', action='store_true', help='å¼ºåˆ¶å¼€å¯pin_memory')
    parser.add_argument('--no-pin-memory', dest='no_pin_memory', action='store_true', help='å¼ºåˆ¶å…³é—­pin_memory')
    # æ–°å¢ï¼šæŸå¤±æƒé‡
    parser.add_argument('--lw-physics', type=float, default=None, help='ç‰©ç†æŸå¤±æƒé‡')
    parser.add_argument('--lw-perceptual', type=float, default=None, help='æ„ŸçŸ¥æŸå¤±æƒé‡')
    parser.add_argument('--lw-edge', type=float, default=None, help='è¾¹ç¼˜æŸå¤±æƒé‡')
    parser.add_argument('--lw-ssim', type=float, default=None, help='SSIMæŸå¤±æƒé‡')
    
    args = parser.parse_args()
    
    try:
        if args.mode == 'interactive':
            print("\n=== æ¨¡å‹è®­ç»ƒç³»ç»Ÿ ===")
            print("1. è®­ç»ƒU-Netæ¨¡å‹")
            print("2. è®­ç»ƒMRA-Netæ¨¡å‹")
            print("3. è¯„ä¼°æ¨¡å‹æ€§èƒ½")
            print("4. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()
        elif args.mode == 'unet':
            choice = '1'
        elif args.mode == 'mranet':
            choice = '2'
        elif args.mode == 'both':
            choice = 'both'
        
        if choice == '1':
            print("\nğŸš€ å¼€å§‹è®­ç»ƒU-Netæ¨¡å‹...")
            
            if args.mode == 'interactive':
                # è·å–ç”¨æˆ·è¾“å…¥
                train_path = input("è®­ç»ƒæ•°æ®é›†è·¯å¾„ [outputs/datasets/train_dataset.h5]: ").strip()
                if not train_path:
                    train_path = "outputs/datasets/train_dataset.h5"
                
                val_path = input("éªŒè¯æ•°æ®é›†è·¯å¾„ [outputs/datasets/val_dataset.h5]: ").strip()
                if not val_path:
                    val_path = "outputs/datasets/val_dataset.h5"
                
                epochs = input("è®­ç»ƒè½®æ•° [100]: ").strip()
                epochs = int(epochs) if epochs else 100
                
                batch_size = input("æ‰¹æ¬¡å¤§å° [8]: ").strip()
                batch_size = int(batch_size) if batch_size else 8
            else:
                # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
                train_path = args.train_path
                val_path = args.val_path
                epochs = args.epochs_unet
                batch_size = args.batch_size_unet
            
            # æ£€æŸ¥æ•°æ®é›†
            if not os.path.exists(train_path):
                print(f"âŒ è®­ç»ƒæ•°æ®é›†ä¸å­˜åœ¨: {train_path}")
                return
            
            # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
            amp_mode = 'on' if args.amp else ('off' if args.no_amp else 'auto')
            pin_memory_mode = 'on' if args.pin_memory else ('off' if args.no_pin_memory else 'auto')
            trainer = ModelTrainer(amp_mode=amp_mode, num_workers=args.num_workers, pin_memory_mode=pin_memory_mode)
            model_path = trainer.train_unet(
                train_dataset_path=train_path,
                val_dataset_path=val_path if os.path.exists(val_path) else None,
                epochs=epochs,
                batch_size=batch_size
            )
            
            print(f"\nâœ… U-Netè®­ç»ƒå®Œæˆ: {model_path}")
            
        elif choice == '2':
            print("\nğŸš€ å¼€å§‹è®­ç»ƒMRA-Netæ¨¡å‹...")
            
            if args.mode == 'interactive':
                # è·å–ç”¨æˆ·è¾“å…¥
                train_path = input("è®­ç»ƒæ•°æ®é›†è·¯å¾„ [outputs/datasets/train_dataset.h5]: ").strip()
                if not train_path:
                    train_path = "outputs/datasets/train_dataset.h5"
                
                val_path = input("éªŒè¯æ•°æ®é›†è·¯å¾„ [outputs/datasets/val_dataset.h5]: ").strip()
                if not val_path:
                    val_path = "outputs/datasets/val_dataset.h5"
                
                epochs = input("è®­ç»ƒè½®æ•° [100]: ").strip()
                epochs = int(epochs) if epochs else 100
                
                batch_size = input("æ‰¹æ¬¡å¤§å° [8]: ").strip()
                batch_size = int(batch_size) if batch_size else 8
            else:
                # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
                train_path = args.train_path
                val_path = args.val_path
                epochs = args.epochs_mranet
                batch_size = args.batch_size_mranet
            
            # æ£€æŸ¥æ•°æ®é›†
            if not os.path.exists(train_path):
                print(f"âŒ è®­ç»ƒæ•°æ®é›†ä¸å­˜åœ¨: {train_path}")
                return
            
            # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
            amp_mode = 'on' if args.amp else ('off' if args.no_amp else 'auto')
            pin_memory_mode = 'on' if args.pin_memory else ('off' if args.no_pin_memory else 'auto')
            trainer = ModelTrainer(amp_mode=amp_mode, num_workers=args.num_workers, pin_memory_mode=pin_memory_mode)
            # ç»„è£…æŸå¤±æƒé‡ï¼ˆä»…å½“æä¾›æ—¶è¦†ç›–é»˜è®¤ï¼‰
            loss_weights = {}
            if args.lw_physics is not None: loss_weights['physics'] = args.lw_physics
            if args.lw_perceptual is not None: loss_weights['perceptual'] = args.lw_perceptual
            if args.lw_edge is not None: loss_weights['edge'] = args.lw_edge
            if args.lw_ssim is not None: loss_weights['ssim'] = args.lw_ssim

            model_path = trainer.train_mra_net(
                train_dataset_path=train_path,
                val_dataset_path=val_path if os.path.exists(val_path) else None,
                epochs=epochs,
                batch_size=batch_size,
                loss_weights=loss_weights if loss_weights else None
            )
            
            print(f"\nâœ… MRA-Netè®­ç»ƒå®Œæˆ: {model_path}")
            
        elif choice == 'both':
            print("\nğŸš€ å¼€å§‹è®­ç»ƒä¸¤ä¸ªæ¨¡å‹...")
            
            # æ£€æŸ¥æ•°æ®é›†
            if not os.path.exists(args.train_path):
                print(f"âŒ è®­ç»ƒæ•°æ®é›†ä¸å­˜åœ¨: {args.train_path}")
                return
            
            amp_mode = 'on' if args.amp else ('off' if args.no_amp else 'auto')
            pin_memory_mode = 'on' if args.pin_memory else ('off' if args.no_pin_memory else 'auto')
            trainer = ModelTrainer(amp_mode=amp_mode, num_workers=args.num_workers, pin_memory_mode=pin_memory_mode)
            
            # è®­ç»ƒU-Net
            print("\nğŸ”¥ ç¬¬1æ­¥: è®­ç»ƒU-Netæ¨¡å‹...")
            unet_path = trainer.train_unet(
                train_dataset_path=args.train_path,
                val_dataset_path=args.val_path if os.path.exists(args.val_path) else None,
                epochs=args.epochs_unet,
                batch_size=args.batch_size_unet
            )
            print(f"âœ… U-Netè®­ç»ƒå®Œæˆ: {unet_path}")
            
            # è®­ç»ƒMRA-Net
            print("\nğŸ”¥ ç¬¬2æ­¥: è®­ç»ƒMRA-Netæ¨¡å‹...")
            # ç»„è£…æŸå¤±æƒé‡ï¼ˆä»…å½“æä¾›æ—¶è¦†ç›–é»˜è®¤ï¼‰
            loss_weights = {}
            if args.lw_physics is not None: loss_weights['physics'] = args.lw_physics
            if args.lw_perceptual is not None: loss_weights['perceptual'] = args.lw_perceptual
            if args.lw_edge is not None: loss_weights['edge'] = args.lw_edge
            if args.lw_ssim is not None: loss_weights['ssim'] = args.lw_ssim

            mranet_path = trainer.train_mra_net(
                train_dataset_path=args.train_path,
                val_dataset_path=args.val_path if os.path.exists(args.val_path) else None,
                epochs=args.epochs_mranet,
                batch_size=args.batch_size_mranet,
                loss_weights=loss_weights if loss_weights else None
            )
            print(f"âœ… MRA-Netè®­ç»ƒå®Œæˆ: {mranet_path}")
            
            print(f"\nğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(f"U-Netæ¨¡å‹: {unet_path}")
            print(f"MRA-Netæ¨¡å‹: {mranet_path}")
            
        elif choice == '3':
            print("\nğŸ“Š æ¨¡å‹è¯„ä¼°åŠŸèƒ½å¼€å‘ä¸­...")
            
        elif choice == '4':
            print("\nğŸ‘‹ é€€å‡ºç¨‹åº")
            
        else:
            print("\nâŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åº")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()